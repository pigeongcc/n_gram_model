# n_gram_model
N-граммная модель для генерации текста с ML-надстройкой


### Запуск
Обучение:
```
python3 train.py --input-dir /path/to/folder/with/txt/files --model /path/where/to/save/model.pkl --N 2

```

Генерация текста:
```
python3 generate.py --model /path/to/model.pkl --prefix "Текст начнется с этой строки" --length 50

```

### Интересные моменты
- Модель принимает параметр N на обучение
- ML-надстройка заключается в кластеризации слов из текстового корпуса по признакам (часть речи, число) на C групп. После кластеризации строится матрица размера C*C, содержащая частоту появления в тексте слова из кластера x вслед за словом из кластера y.


### Проблемы, с которыми я столкнулся
- Не успел обернуть модель и датасет в классы
- Не успел завести больше признаков для слов в ML-модели: род, падеж и др.


### Примеры работы
